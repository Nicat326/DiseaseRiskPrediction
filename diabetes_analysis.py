# -*- coding: utf-8 -*-
"""
Diabetes Risk Prediction Analysis
=================================

Bu notebook diabetes dataset Ã¼zÉ™rindÉ™ hÉ™rtÉ™rÉ™fli data science analizi aparÄ±r.
TÉ™qdim olunan tÉ™lÉ™blÉ™rÉ™ É™sasÉ™n aÅŸaÄŸÄ±dakÄ± metodlarÄ± tÉ™tbiq edir:

1. Pandasla mÉ™lumatlarÄ±n dÃ¼zgÃ¼n oxunmasÄ±
2. Statistik data types vÉ™ vizuallaÅŸdÄ±rmalar daxil olmaqla, datasetin xÃ¼susiyyÉ™tlÉ™rini baÅŸa dÃ¼ÅŸmÉ™k Ã¼Ã§Ã¼n EDA
3. Data Cleaning - null dÉ™yÉ™rlÉ™rin yoxlanÄ±lmasÄ±, onlarÄ±n dÃ¼zgÃ¼n vÉ™ mÉ™ntiqi idarÉ™ edilmÉ™si
4. Data Preprocessing and Feature Engineering - UyÄŸun encoding Ã¼sullarÄ±ndan istifadÉ™ edilmÉ™si
5. Data Preprocessing and Feature Engineering - scaling/normalizing numerical features
6. Feature Selection - MaÅŸÄ±n Ã¶yrÉ™nmÉ™ modelinq Ã¼Ã§Ã¼n mÃ¼vafiq featurelarÄ± seÃ§in
7. Splitting the Data - datasetin train vÉ™ test setlÉ™rinÉ™ bÃ¶lÃ¼n
8. DÃ¼zgÃ¼n maÅŸÄ±n Ã¶yrÉ™nmÉ™ modelinin seÃ§ilmÉ™si (mÃ¼mkÃ¼nsÉ™ 2 model)
9. HÉ™r bir modelin test dataseti Ã¼zÉ™rindÉ™ testi
10. Model Evaluation - Test dÉ™stindÉ™ mÃ¼vÉ™ffÉ™q Ã¶lÃ§Ã¼lÉ™rdÉ™n istifadÉ™ edÉ™rÉ™k model performansÄ±nÄ± qiymÉ™tlÉ™ndirin
"""

# LazÄ±mi kitabxanalarÄ± import edirik
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.feature_selection import SelectKBest, f_classif
import warnings
warnings.filterwarnings('ignore')

# Matplotlib Ã¼Ã§Ã¼n AzÉ™rbaycan dili dÉ™stÉ™yi
plt.rcParams['font.family'] = 'DejaVu Sans'
sns.set_style("whitegrid")

print("=" * 60)
print("DIABETES RISK PREDICTION ANALYSIS")
print("=" * 60)

# 1. PANDASLA MÆLUMATLARIN DÃœZGÃœN OXUNMASI
print("\n1. MÆLUMATLAR YÃœKLÆNIR...")
df = pd.read_csv('c:/Users/hp/CascadeProjects/DiseaseRiskPrediction/data/diabetes.csv')
print(f"âœ“ Dataset uÄŸurla yÃ¼klÉ™ndi: {df.shape[0]} sÉ™tir, {df.shape[1]} sÃ¼tun")

# 2. STATISTIK DATA TYPES VÆ VÄ°ZUALLAÅDIRMALAR - EDA
print("\n2. EXPLORATORY DATA ANALYSIS (EDA)")
print("-" * 40)

# Dataset haqqÄ±nda É™sas mÉ™lumatlar
print("Dataset strukturu:")
print(df.info())
print("\nÄ°lk 5 sÉ™tir:")
print(df.head())

print("\nStatistik xÃ¼lasÉ™:")
print(df.describe())

# Target dÉ™yiÅŸÉ™ninin paylanmasÄ±
print(f"\nTarget dÉ™yiÅŸÉ™n (Outcome) paylanmasÄ±:")
print(df['Outcome'].value_counts())
print(f"Diabetes olan: {df['Outcome'].sum()} ({df['Outcome'].mean()*100:.1f}%)")
print(f"Diabetes olmayan: {len(df) - df['Outcome'].sum()} ({(1-df['Outcome'].mean())*100:.1f}%)")

# VizuallaÅŸdÄ±rmalar
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Target dÉ™yiÅŸÉ™ninin paylanmasÄ±
axes[0,0].pie(df['Outcome'].value_counts(), labels=['Diabetes Yox', 'Diabetes Var'], 
              autopct='%1.1f%%', startangle=90, colors=['lightblue', 'lightcoral'])
axes[0,0].set_title('Diabetes PaylanmasÄ±')

# YaÅŸ paylanmasÄ±
axes[0,1].hist(df['Age'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')
axes[0,1].set_title('YaÅŸ PaylanmasÄ±')
axes[0,1].set_xlabel('YaÅŸ')
axes[0,1].set_ylabel('Tezlik')

# BMI paylanmasÄ±
axes[1,0].hist(df['BMI'], bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
axes[1,0].set_title('BMI PaylanmasÄ±')
axes[1,0].set_xlabel('BMI')
axes[1,0].set_ylabel('Tezlik')

# Glucose paylanmasÄ±
axes[1,1].hist(df['Glucose'], bins=20, alpha=0.7, color='orange', edgecolor='black')
axes[1,1].set_title('Glucose PaylanmasÄ±')
axes[1,1].set_xlabel('Glucose')
axes[1,1].set_ylabel('Tezlik')

plt.tight_layout()
plt.show()

# Korelasiya matrisi
plt.figure(figsize=(12, 10))
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, 
            square=True, linewidths=0.5)
plt.title('XÃ¼susiyyÉ™tlÉ™r ArasÄ±nda Korelasiya Matrisi')
plt.show()

# 3. DATA CLEANING - NULL DÆYÆRLÆRÄ°N YOXLANILMASI
print("\n3. DATA CLEANING")
print("-" * 40)

print("Null dÉ™yÉ™rlÉ™r:")
null_counts = df.isnull().sum()
print(null_counts)

if null_counts.sum() == 0:
    print("âœ“ HeÃ§ bir null dÉ™yÉ™r tapÄ±lmadÄ±!")
else:
    print("âš  Null dÉ™yÉ™rlÉ™r tapÄ±ldÄ± vÉ™ tÉ™mizlÉ™nÉ™cÉ™k...")
    df = df.dropna()

# SÄ±fÄ±r dÉ™yÉ™rlÉ™rin yoxlanÄ±lmasÄ± (bÉ™zi sahÉ™lÉ™rdÉ™ sÄ±fÄ±r mÉ™nasÄ±z ola bilÉ™r)
print("\nSÄ±fÄ±r dÉ™yÉ™rlÉ™rin sayÄ±:")
zero_counts = (df == 0).sum()
print(zero_counts)

# Bioloji olaraq sÄ±fÄ±r ola bilmÉ™yÉ™n sahÉ™lÉ™ri mÃ¼É™yyÉ™n edirik
biological_fields = ['Glucose', 'BloodPressure', 'SkinThickness', 'BMI']
print(f"\nBioloji olaraq sÄ±fÄ±r ola bilmÉ™yÉ™n sahÉ™lÉ™rdÉ™ sÄ±fÄ±r dÉ™yÉ™rlÉ™r:")
for field in biological_fields:
    if field in df.columns:
        zero_count = (df[field] == 0).sum()
        if zero_count > 0:
            print(f"{field}: {zero_count} sÄ±fÄ±r dÉ™yÉ™r")
            # SÄ±fÄ±r dÉ™yÉ™rlÉ™ri median ilÉ™ É™vÉ™z edirik
            median_val = df[df[field] != 0][field].median()
            df[field] = df[field].replace(0, median_val)
            print(f"  â†’ {field} sahÉ™sindÉ™ki sÄ±fÄ±r dÉ™yÉ™rlÉ™r median ({median_val:.2f}) ilÉ™ É™vÉ™z edildi")

print("âœ“ Data cleaning tamamlandÄ±!")

# 4. DATA PREPROCESSING AND FEATURE ENGINEERING - ENCODING
print("\n4. DATA PREPROCESSING VÆ FEATURE ENGINEERING")
print("-" * 40)

# Yeni xÃ¼susiyyÉ™tlÉ™r yaradÄ±rÄ±q
print("Yeni xÃ¼susiyyÉ™tlÉ™r yaradÄ±lÄ±r...")

# BMI kateqoriyalarÄ±
def categorize_bmi(bmi):
    if bmi < 18.5:
        return 0  # Underweight
    elif bmi < 25:
        return 1  # Normal
    elif bmi < 30:
        return 2  # Overweight
    else:
        return 3  # Obese

df['BMI_Category'] = df['BMI'].apply(categorize_bmi)

# YaÅŸ qruplarÄ±
def categorize_age(age):
    if age < 30:
        return 0  # Young
    elif age < 50:
        return 1  # Middle-aged
    else:
        return 2  # Senior

df['Age_Group'] = df['Age'].apply(categorize_age)

# Glucose sÉ™viyyÉ™si kateqoriyalarÄ±
def categorize_glucose(glucose):
    if glucose < 100:
        return 0  # Normal
    elif glucose < 126:
        return 1  # Prediabetes
    else:
        return 2  # Diabetes

df['Glucose_Category'] = df['Glucose'].apply(categorize_glucose)

print("âœ“ Yeni xÃ¼susiyyÉ™tlÉ™r yaradÄ±ldÄ±: BMI_Category, Age_Group, Glucose_Category")

# 5. SCALING/NORMALIZING NUMERICAL FEATURES
print("\n5. NUMERICAL FEATURES SCALING")
print("-" * 40)

# Numerical sÃ¼tunlarÄ± mÃ¼É™yyÉ™n edirik
numerical_features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 
                     'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']

# Scaling Ã¼Ã§Ã¼n StandardScaler istifadÉ™ edirik
scaler = StandardScaler()
df_scaled = df.copy()
df_scaled[numerical_features] = scaler.fit_transform(df[numerical_features])

print("âœ“ Numerical xÃ¼susiyyÉ™tlÉ™r StandardScaler ilÉ™ normallaÅŸdÄ±rÄ±ldÄ±")

# 6. FEATURE SELECTION
print("\n6. FEATURE SELECTION")
print("-" * 40)

# BÃ¼tÃ¼n xÃ¼susiyyÉ™tlÉ™ri seÃ§irik (target istisna olmaqla)
feature_columns = [col for col in df_scaled.columns if col != 'Outcome']
X = df_scaled[feature_columns]
y = df_scaled['Outcome']

# SelectKBest ilÉ™ É™n yaxÅŸÄ± xÃ¼susiyyÉ™tlÉ™ri seÃ§irik
selector = SelectKBest(score_func=f_classif, k=8)
X_selected = selector.fit_transform(X, y)

# SeÃ§ilmiÅŸ xÃ¼susiyyÉ™tlÉ™rin adlarÄ±nÄ± alÄ±rÄ±q
selected_features = [feature_columns[i] for i in selector.get_support(indices=True)]
print(f"SeÃ§ilmiÅŸ xÃ¼susiyyÉ™tlÉ™r ({len(selected_features)}):")
for i, feature in enumerate(selected_features):
    score = selector.scores_[feature_columns.index(feature)]
    print(f"  {i+1}. {feature}: {score:.2f}")

# 7. SPLITTING THE DATA
print("\n7. DATA SPLITTING")
print("-" * 40)

X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2, random_state=42, stratify=y
)

print(f"âœ“ Data bÃ¶lÃ¼ndÃ¼:")
print(f"  Training set: {X_train.shape[0]} nÃ¼munÉ™")
print(f"  Test set: {X_test.shape[0]} nÃ¼munÉ™")
print(f"  Training set diabetes nisbÉ™ti: {y_train.mean():.3f}")
print(f"  Test set diabetes nisbÉ™ti: {y_test.mean():.3f}")

# 8. MAÅIN Ã–YRÆNMÆ MODELLÆRÄ°NÄ°N SEÃ‡Ä°LMÆSÄ° VÆ TÆLÄ°MÄ°
print("\n8. MAÅIN Ã–YRÆNMÆ MODELLÆRÄ°")
print("-" * 40)

# Model 1: Random Forest Classifier
print("Model 1: Random Forest Classifier tÉ™lim alÄ±r...")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
print("âœ“ Random Forest modeli tÉ™lim aldÄ±")

# Model 2: Logistic Regression
print("Model 2: Logistic Regression tÉ™lim alÄ±r...")
lr_model = LogisticRegression(random_state=42, max_iter=1000)
lr_model.fit(X_train, y_train)
print("âœ“ Logistic Regression modeli tÉ™lim aldÄ±")

# 9. HÆR BÄ°R MODELÄ°N TEST DATASETÄ° ÃœZÆRÄ°NDÆ TESTÄ°
print("\n9. MODEL TESLÆRÄ°")
print("-" * 40)

# Random Forest tÉ™xminlÉ™ri
rf_predictions = rf_model.predict(X_test)
rf_probabilities = rf_model.predict_proba(X_test)[:, 1]

# Logistic Regression tÉ™xminlÉ™ri
lr_predictions = lr_model.predict(X_test)
lr_probabilities = lr_model.predict_proba(X_test)[:, 1]

print("âœ“ HÉ™r iki model test dataseti Ã¼zÉ™rindÉ™ tÉ™xmin etdi")

# 10. MODEL EVALUATION
print("\n10. MODEL PERFORMANS QÄ°YMÆTLÆNDÄ°RMÆSÄ°")
print("=" * 60)

def evaluate_model(y_true, y_pred, model_name):
    """Model performansÄ±nÄ± qiymÉ™tlÉ™ndir"""
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    
    print(f"\n{model_name} PerformansÄ±:")
    print(f"  Accuracy (DÉ™qiqlik):  {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"  Precision (Presizlik): {precision:.4f} ({precision*100:.2f}%)")
    print(f"  Recall (HÉ™ssaslÄ±q):    {recall:.4f} ({recall*100:.2f}%)")
    print(f"  F1-Score:              {f1:.4f} ({f1*100:.2f}%)")
    
    return accuracy, precision, recall, f1

# Random Forest qiymÉ™tlÉ™ndirmÉ™si
rf_metrics = evaluate_model(y_test, rf_predictions, "Random Forest")

# Logistic Regression qiymÉ™tlÉ™ndirmÉ™si  
lr_metrics = evaluate_model(y_test, lr_predictions, "Logistic Regression")

# Confusion Matrix vizuallaÅŸdÄ±rmasÄ±
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Random Forest Confusion Matrix
cm_rf = confusion_matrix(y_test, rf_predictions)
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', ax=axes[0])
axes[0].set_title('Random Forest - Confusion Matrix')
axes[0].set_xlabel('TÉ™xmin edilÉ™n')
axes[0].set_ylabel('HÉ™qiqi')

# Logistic Regression Confusion Matrix
cm_lr = confusion_matrix(y_test, lr_predictions)
sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Greens', ax=axes[1])
axes[1].set_title('Logistic Regression - Confusion Matrix')
axes[1].set_xlabel('TÉ™xmin edilÉ™n')
axes[1].set_ylabel('HÉ™qiqi')

plt.tight_layout()
plt.show()

# Detailed Classification Report
print("\nÆTRAFLI KLASSÄ°FÄ°KASÄ°YA HESABATI:")
print("\nRandom Forest:")
print(classification_report(y_test, rf_predictions, target_names=['Diabetes Yox', 'Diabetes Var']))

print("\nLogistic Regression:")
print(classification_report(y_test, lr_predictions, target_names=['Diabetes Yox', 'Diabetes Var']))

# Feature Importance (Random Forest Ã¼Ã§Ã¼n)
print("\nXÃœSUSÄ°YYÆTLÆRÄ°N ÆHÆMÄ°YYÆTÄ° (Random Forest):")
feature_importance = pd.DataFrame({
    'feature': selected_features,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print(feature_importance)

# Feature Importance vizuallaÅŸdÄ±rmasÄ±
plt.figure(figsize=(10, 6))
sns.barplot(data=feature_importance, x='importance', y='feature', palette='viridis')
plt.title('XÃ¼susiyyÉ™tlÉ™rin ÆhÉ™miyyÉ™ti (Random Forest)')
plt.xlabel('ÆhÉ™miyyÉ™t')
plt.tight_layout()
plt.show()

# Model mÃ¼qayisÉ™si
print("\nMODEL MÃœQAYÄ°SÆSÄ°:")
print("-" * 40)
comparison_df = pd.DataFrame({
    'Model': ['Random Forest', 'Logistic Regression'],
    'Accuracy': [rf_metrics[0], lr_metrics[0]],
    'Precision': [rf_metrics[1], lr_metrics[1]],
    'Recall': [rf_metrics[2], lr_metrics[2]],
    'F1-Score': [rf_metrics[3], lr_metrics[3]]
})

print(comparison_df.round(4))

# Æn yaxÅŸÄ± modeli mÃ¼É™yyÉ™n edirik
best_model_idx = comparison_df['F1-Score'].idxmax()
best_model_name = comparison_df.loc[best_model_idx, 'Model']
print(f"\nğŸ† Æn yaxÅŸÄ± model: {best_model_name}")
print(f"   F1-Score: {comparison_df.loc[best_model_idx, 'F1-Score']:.4f}")

print("\n" + "=" * 60)
print("ANALÄ°Z TAMAMLANDI!")
print("=" * 60)
print("\nXÃœLASÆ:")
print("âœ“ Dataset uÄŸurla yÃ¼klÉ™ndi vÉ™ tÉ™hlil edildi")
print("âœ“ Data cleaning vÉ™ preprocessing aparÄ±ldÄ±")
print("âœ“ Feature engineering vÉ™ selection tÉ™tbiq edildi")
print("âœ“ Ä°ki mÃ¼xtÉ™lif maÅŸÄ±n Ã¶yrÉ™nmÉ™ modeli tÉ™lim aldÄ±")
print("âœ“ ModellÉ™r test edildi vÉ™ performanslarÄ± qiymÉ™tlÉ™ndirildi")
print(f"âœ“ Æn yaxÅŸÄ± model: {best_model_name}")
